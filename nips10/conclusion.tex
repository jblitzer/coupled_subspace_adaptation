\section{Conclusion}
\label{sec:conclusion}

Domain adaptation algorithms have been extensively studied in nearly
every field of applied machine learning.  What we formalized here, for
the first time, is how to adapt from source to target when crucial
target features do not have support under the source distribution.
Our formalization leads us to suggest a simple algorithm for
adaptation based on a low-dimensional coupled subspace.  Under natural
assumptions, this algorithm allows us to learn an optimal target
predictor from labeled source data and unlabeled target data.
Furthermore, we show that incorporating small amounts of labeled
target data can improve the stability of our target predictor, both
theoretically and empirically.  We believe our analysis will lead to
interesting connections to other work on adaptation and transfer
learning, especially supervised shared subspace
methods~\cite{argyriou07,daume07}.
